#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Sistema de Detec√ß√£o de Ataques de Rede em Tempo Real - MiniLM
Otimizado para Raspberry Pi e dispositivos IoT
"""

import onnxruntime as ort
import numpy as np
import pandas as pd
import pickle
import time
import argparse
import json
from datetime import datetime
import threading
import queue
import sys
import psutil
import os

class MiniLMNetworkDetector:
    def __init__(self, model_path, metadata_path):
        """Inicializar detector de ataques MiniLM"""
        
        print("üöÄ Carregando modelo MiniLM...")
        
        # Configurar ONNX Runtime para efici√™ncia m√°xima
        providers = ['CPUExecutionProvider']
        sess_options = ort.SessionOptions()
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL
        sess_options.intra_op_num_threads = psutil.cpu_count()
        
        self.session = ort.InferenceSession(
            model_path, 
            sess_options=sess_options,
            providers=providers
        )
        
        print("üìä Carregando metadados...")
        with open(metadata_path, 'rb') as f:
            self.metadata = pickle.load(f)
        
        self.scaler = self.metadata['scaler']
        self.label_encoder = self.metadata['label_encoder']
        self.feature_names = self.metadata['feature_names']
        self.classes = self.metadata['classes']
        
        print(f"‚úÖ Modelo MiniLM carregado com sucesso!")
        print(f"üìã Classes detect√°veis: {self.classes}")
        print(f"üîß Features: {len(self.feature_names)}")
        
        # Estat√≠sticas de performance
        self.total_predictions = 0
        self.attack_detections = 0
        self.inference_times = []
        self.memory_usage = []
        
        # Warm-up do modelo
        self._warmup()
    
    def _warmup(self):
        """Warm-up do modelo para otimizar performance"""
        print("üî• Aquecendo modelo...")
        dummy_features = {name: np.random.randn() for name in self.feature_names}
        
        # Executar algumas predi√ß√µes para warm-up
        for _ in range(10):
            self.predict(dummy_features, verbose=False)
        
        print("‚úÖ Warm-up conclu√≠do!")
    
    def preprocess_features(self, features_dict):
        """Pr√©-processar features de entrada"""
        
        # Converter para array na ordem correta
        features_array = np.array([features_dict.get(name, 0.0) for name in self.feature_names])
        
        # Normalizar usando o scaler treinado
        features_scaled = self.scaler.transform(features_array.reshape(1, -1))
        
        return features_scaled.astype(np.float32)
    
    def predict(self, features_dict, verbose=True):
        """Fazer predi√ß√£o de ataque"""
        
        # Pr√©-processar
        features = self.preprocess_features(features_dict)
        
        # Medir uso de mem√≥ria antes da infer√™ncia
        memory_before = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # Infer√™ncia
        start_time = time.time()
        ort_inputs = {'features': features}
        logits, probabilities = self.session.run(None, ort_inputs)
        inference_time = (time.time() - start_time) * 1000  # ms
        
        # Medir uso de mem√≥ria ap√≥s a infer√™ncia
        memory_after = psutil.Process().memory_info().rss / 1024 / 1024  # MB
        
        # Processar resultado
        predicted_class_idx = np.argmax(probabilities[0])
        predicted_class = self.classes[predicted_class_idx]
        confidence = probabilities[0][predicted_class_idx]
        
        # Atualizar estat√≠sticas
        self.total_predictions += 1
        self.inference_times.append(inference_time)
        self.memory_usage.append(memory_after)
        
        is_attack = predicted_class.lower() != 'benign'
        if is_attack:
            self.attack_detections += 1
        
        result = {
            'timestamp': datetime.now().isoformat(),
            'model': 'MiniLM',
            'predicted_class': predicted_class,
            'confidence': float(confidence),
            'is_attack': is_attack,
            'inference_time_ms': inference_time,
            'memory_usage_mb': memory_after,
            'all_probabilities': probabilities[0].tolist()
        }
        
        if verbose and inference_time > 10:  # Alertar se lat√™ncia alta
            print(f"‚ö†Ô∏è Lat√™ncia alta detectada: {inference_time:.2f}ms")
        
        return result
    
    def get_statistics(self):
        """Obter estat√≠sticas detalhadas do detector"""
        
        if not self.inference_times:
            return {}
        
        return {
            'model': 'MiniLM',
            'total_predictions': self.total_predictions,
            'attack_detections': self.attack_detections,
            'attack_rate': self.attack_detections / self.total_predictions if self.total_predictions > 0 else 0,
            'avg_inference_time_ms': np.mean(self.inference_times),
            'max_inference_time_ms': np.max(self.inference_times),
            'min_inference_time_ms': np.min(self.inference_times),
            'std_inference_time_ms': np.std(self.inference_times),
            'throughput_per_second': 1000 / np.mean(self.inference_times),
            'avg_memory_usage_mb': np.mean(self.memory_usage),
            'max_memory_usage_mb': np.max(self.memory_usage),
            'cpu_count': psutil.cpu_count(),
            'system_memory_gb': psutil.virtual_memory().total / 1024 / 1024 / 1024
        }

class RealTimeMonitor:
    def __init__(self, detector, log_file='minilm_attack_log.json'):
        self.detector = detector
        self.log_file = log_file
        self.data_queue = queue.Queue(maxsize=1000)  # Buffer limitado
        self.running = False
        self.stats_interval = 100  # Mostrar stats a cada 100 predi√ß√µes
    
    def log_detection(self, result):
        """Registrar detec√ß√£o em arquivo"""
        
        try:
            with open(self.log_file, 'a', encoding='utf-8') as f:
                f.write(json.dumps(result, ensure_ascii=False) + '\n')
        except Exception as e:
            print(f"‚ùå Erro ao salvar log: {e}")
    
    def process_data_stream(self):
        """Processar stream de dados em tempo real"""
        
        while self.running:
            try:
                # Obter dados da fila
                features_dict = self.data_queue.get(timeout=1)
                
                # Fazer predi√ß√£o
                result = self.detector.predict(features_dict)
                
                # Log e alertas
                if result['is_attack']:
                    print(f"üö® ATAQUE DETECTADO: {result['predicted_class']} "
                          f"(Confian√ßa: {result['confidence']:.3f}, "
                          f"Lat√™ncia: {result['inference_time_ms']:.1f}ms)")
                    self.log_detection(result)
                else:
                    if self.detector.total_predictions % 50 == 0:  # Log peri√≥dico
                        print(f"‚úÖ Tr√°fego normal (Confian√ßa: {result['confidence']:.3f})")
                
                # Mostrar estat√≠sticas periodicamente
                if self.detector.total_predictions % self.stats_interval == 0:
                    self._show_stats()
                
                self.data_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"‚ùå Erro no processamento: {e}")
    
    def _show_stats(self):
        """Mostrar estat√≠sticas em tempo real"""
        stats = self.detector.get_statistics()
        print(f"\nüìä ESTAT√çSTICAS (MiniLM)")
        print(f"   Predi√ß√µes: {stats['total_predictions']}")
        print(f"   Ataques: {stats['attack_detections']} ({stats['attack_rate']:.1%})")
        print(f"   Lat√™ncia: {stats['avg_inference_time_ms']:.1f}ms (¬±{stats['std_inference_time_ms']:.1f})")
        print(f"   Throughput: {stats['throughput_per_second']:.1f}/s")
        print(f"   Mem√≥ria: {stats['avg_memory_usage_mb']:.1f}MB")
    
    def start_monitoring(self):
        """Iniciar monitoramento"""
        
        self.running = True
        monitor_thread = threading.Thread(target=self.process_data_stream, daemon=True)
        monitor_thread.start()
        
        print("üéØ Monitoramento MiniLM iniciado...")
        return monitor_thread
    
    def stop_monitoring(self):
        """Parar monitoramento"""
        self.running = False
        print("üõë Monitoramento parado.")
    
    def add_data(self, features_dict):
        """Adicionar dados para an√°lise"""
        try:
            self.data_queue.put_nowait(features_dict)
        except queue.Full:
            print("‚ö†Ô∏è Buffer cheio, descartando amostra antiga...")
            try:
                self.data_queue.get_nowait()
                self.data_queue.put_nowait(features_dict)
            except queue.Empty:
                pass

def run_benchmark(detector, num_samples=1000):
    """Executar benchmark de performance"""
    
    print(f"üèÉ Executando benchmark MiniLM com {num_samples} amostras...")
    
    # Gerar dados de teste
    test_data = []
    for _ in range(num_samples):
        features = {name: np.random.randn() for name in detector.feature_names}
        test_data.append(features)
    
    # Executar benchmark
    start_time = time.time()
    
    for i, features in enumerate(test_data):
        detector.predict(features, verbose=False)
        
        if (i + 1) % 100 == 0:
            progress = (i + 1) / num_samples * 100
            print(f"   Progresso: {progress:.1f}%")
    
    total_time = time.time() - start_time
    
    # Resultados
    stats = detector.get_statistics()
    print(f"\nüèÜ RESULTADOS DO BENCHMARK (MiniLM)")
    print(f"   Amostras processadas: {stats['total_predictions']}")
    print(f"   Tempo total: {total_time:.2f}s")
    print(f"   Lat√™ncia m√©dia: {stats['avg_inference_time_ms']:.2f}ms")
    print(f"   Lat√™ncia m√≠n/m√°x: {stats['min_inference_time_ms']:.2f}/{stats['max_inference_time_ms']:.2f}ms")
    print(f"   Throughput: {stats['throughput_per_second']:.1f} predi√ß√µes/segundo")
    print(f"   Mem√≥ria m√©dia: {stats['avg_memory_usage_mb']:.1f}MB")
    print(f"   Mem√≥ria m√°xima: {stats['max_memory_usage_mb']:.1f}MB")

def simulate_network_data(csv_file, detector, monitor, delay=0.1):
    """Simular dados de rede em tempo real"""
    
    print(f"üìÅ Carregando dados de simula√ß√£o: {csv_file}")
    try:
        df = pd.read_csv(csv_file)
    except Exception as e:
        print(f"‚ùå Erro ao carregar arquivo: {e}")
        return
    
    print(f"üé¨ Iniciando simula√ß√£o com {len(df)} amostras (delay: {delay}s)...")
    
    for idx, row in df.iterrows():
        if not monitor.running:
            break
            
        # Converter linha para dicion√°rio (excluindo label se existir)
        features_dict = row.drop('label', errors='ignore').to_dict()
        
        # Adicionar √† fila de monitoramento
        monitor.add_data(features_dict)
        
        # Mostrar progresso
        if (idx + 1) % 500 == 0:
            progress = (idx + 1) / len(df) * 100
            print(f"üìà Progresso: {progress:.1f}% ({idx + 1}/{len(df)})")
        
        time.sleep(delay)
    
    print("‚úÖ Simula√ß√£o conclu√≠da!")

def main():
    parser = argparse.ArgumentParser(description='Detector de Ataques MiniLM em Tempo Real')
    parser.add_argument('--model', default='minilm_attack_detector_quantized.onnx', 
                       help='Modelo ONNX do MiniLM')
    parser.add_argument('--metadata', default='minilm_metadata.pkl', 
                       help='Metadados do modelo')
    parser.add_argument('--simulate', type=str, 
                       help='Arquivo CSV para simula√ß√£o')
    parser.add_argument('--delay', type=float, default=0.1, 
                       help='Delay entre amostras (segundos)')
    parser.add_argument('--benchmark', action='store_true', 
                       help='Executar benchmark de performance')
    parser.add_argument('--samples', type=int, default=1000,
                       help='N√∫mero de amostras para benchmark')
    parser.add_argument('--interactive', action='store_true', 
                       help='Modo interativo')
    
    args = parser.parse_args()
    
    # Verificar se arquivos existem
    if not os.path.exists(args.model):
        print(f"‚ùå Modelo n√£o encontrado: {args.model}")
        print("üí° Execute o notebook MiniLM_optimization.ipynb primeiro!")
        sys.exit(1)
    
    if not os.path.exists(args.metadata):
        print(f"‚ùå Metadados n√£o encontrados: {args.metadata}")
        sys.exit(1)
    
    # Inicializar detector
    try:
        detector = MiniLMNetworkDetector(args.model, args.metadata)
        monitor = RealTimeMonitor(detector)
    except Exception as e:
        print(f"‚ùå Erro ao inicializar detector MiniLM: {e}")
        sys.exit(1)
    
    if args.benchmark:
        run_benchmark(detector, args.samples)
        
    elif args.simulate:
        if not os.path.exists(args.simulate):
            print(f"‚ùå Arquivo de simula√ß√£o n√£o encontrado: {args.simulate}")
            sys.exit(1)
            
        monitor_thread = monitor.start_monitoring()
        
        try:
            simulate_network_data(args.simulate, detector, monitor, args.delay)
        except KeyboardInterrupt:
            print("\nüõë Interrompido pelo usu√°rio")
        finally:
            monitor.stop_monitoring()
            
            # Mostrar estat√≠sticas finais
            stats = detector.get_statistics()
            print(f"\nüìä ESTAT√çSTICAS FINAIS (MiniLM)")
            for key, value in stats.items():
                if isinstance(value, float):
                    print(f"   {key}: {value:.3f}")
                else:
                    print(f"   {key}: {value}")
    
    elif args.interactive:
        print("\nüéÆ Modo interativo MiniLM ativado.")
        print("Pressione Enter para gerar predi√ß√µes com dados aleat√≥rios...")
        
        while True:
            try:
                input("‚èé Enter para predi√ß√£o (Ctrl+C para sair): ")
                
                # Gerar features aleat√≥rias
                test_features = {name: np.random.randn() for name in detector.feature_names}
                result = detector.predict(test_features)
                
                print(f"\nüîç RESULTADO:")
                print(f"   Classe: {result['predicted_class']}")
                print(f"   Confian√ßa: {result['confidence']:.3f}")
                print(f"   √â ataque: {'üö® SIM' if result['is_attack'] else '‚úÖ N√ÉO'}")
                print(f"   Lat√™ncia: {result['inference_time_ms']:.2f}ms")
                print(f"   Mem√≥ria: {result['memory_usage_mb']:.1f}MB")
                
            except KeyboardInterrupt:
                break
    
    else:
        print("‚ùì Use --simulate, --interactive ou --benchmark")
        parser.print_help()

if __name__ == '__main__':
    main() 